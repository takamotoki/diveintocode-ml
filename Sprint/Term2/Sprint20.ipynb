{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Sprint20.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyM6v/PZu+Ge+/L6pnd0Xf55"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"1C8TMg2SfiU8"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wpaEopytfo0t"},"source":["### 【問題1】コードレビュー\n","転移学習を使用してセグメンテーションの精度を改善したコードを提示するので、レビューを行ってください。\n","\n","\n","《視点例》\n","\n","\n","- 前回使用した実装とはどのように違うのか\n","- 転移学習をどのように行っているか"]},{"cell_type":"markdown","metadata":{"id":"lVLT5X1ES8zQ"},"source":["- 前回(Sprint19)のU-Net"]},{"cell_type":"code","metadata":{"id":"pCR2IHWCS-Fm"},"source":["\"\"\"\n","def unet(pretrained_weights = None,input_size = (256,256,1)):\n","    inputs = Input(input_size)\n","    conv1 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(inputs)\n","    conv1 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv1)\n","    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n","    conv2 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool1)\n","    conv2 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv2)\n","    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n","    conv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool2)\n","    conv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv3)\n","    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n","    conv4 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool3)\n","    conv4 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv4)\n","    drop4 = Dropout(0.5)(conv4)\n","    pool4 = MaxPooling2D(pool_size=(2, 2))(drop4)\n","\n","    conv5 = Conv2D(1024, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool4)\n","    conv5 = Conv2D(1024, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv5)\n","    drop5 = Dropout(0.5)(conv5)\n","\n","    up6 = Conv2D(512, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(drop5))\n","    merge6 = concatenate([drop4,up6], axis = 3)\n","    conv6 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge6)\n","    conv6 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv6)\n","\n","    up7 = Conv2D(256, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv6))\n","    merge7 = concatenate([conv3,up7], axis = 3)\n","    conv7 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge7)\n","    conv7 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv7)\n","\n","    up8 = Conv2D(128, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv7))\n","    merge8 = concatenate([conv2,up8], axis = 3)\n","    conv8 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge8)\n","    conv8 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv8)\n","\n","    up9 = Conv2D(64, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv8))\n","    merge9 = concatenate([conv1,up9], axis = 3)\n","    conv9 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge9)\n","    conv9 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)\n","    conv9 = Conv2D(2, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)\n","    conv10 = Conv2D(1, 1, activation = 'sigmoid')(conv9)\n","\n","    model = Model(input = inputs, output = conv10)\n","\n","    model.compile(optimizer = Adam(lr = 1e-4), loss = 'binary_crossentropy', metrics = ['accuracy'])\n","    \n","    #model.summary()\n","\n","    if(pretrained_weights):\n","    \tmodel.load_weights(pretrained_weights)\n","\n","    return model\n","\"\"\""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"OrrjSLObTINn"},"source":["- 今回(Sprint20)のResNet"]},{"cell_type":"code","metadata":{"id":"x2vFh8wWfriz","executionInfo":{"status":"ok","timestamp":1601440671681,"user_tz":-540,"elapsed":806,"user":{"displayName":"Takahiro Motoki","photoUrl":"","userId":"15598172162740427386"}},"outputId":"0c3222ff-dd39-467d-8291-22a730899ab5","colab":{"base_uri":"https://localhost:8080/","height":120}},"source":["\"\"\"\n","# Basic decoder block with Conv, BN and PReLU activation.\n","def decoder_block_simple(\n","        layer_name, block_name,\n","        num_filters=32,\n","        conv_dim=(3, 3)):\n","\n","    x_dec = Conv2D(\n","        num_filters, conv_dim,\n","        padding='same',\n","        name='{}_conv'.format(block_name))(layer_name)\n","    x_dec = BatchNormalization(\n","        name='{}_bn'.format(block_name))(x_dec)\n","    x_dec = PReLU(\n","        name='{}_activation'.format(block_name))(x_dec)\n","\n","    return x_dec\n","\n","# Decoder block with bottleneck architecture, where middle conv layer\n","# is half the size of first and last, in order to compress representation.\n","# This type of architecture is supposed to retain most useful information.\n","def decoder_block_bottleneck(\n","        layer_name, block_name,\n","        num_filters=32,\n","        conv_dim=(3, 3),\n","        dropout_frac=0.2):\n","\n","    x_dec = Conv2D(\n","        num_filters, conv_dim,\n","        padding='same',\n","        name='{}_conv1'.format(block_name))(layer_name)\n","    x_dec = BatchNormalization(\n","        name='{}_bn1'.format(block_name))(x_dec)\n","    x_dec = PReLU(\n","        name='{}_activation1'.format(block_name))(x_dec)\n","    x_dec = Dropout(dropout_frac)(x_dec)\n","\n","    x_dec2 = Conv2D(\n","        num_filters // 2, conv_dim,\n","        padding='same',\n","        name='{}_conv2'.format(block_name))(x_dec)\n","    x_dec2 = BatchNormalization(\n","        name='{}_bn2'.format(block_name))(x_dec2)\n","    x_dec2 = PReLU(\n","        name='{}_activation2'.format(block_name))(x_dec2)\n","    x_dec2 = Dropout(dropout_frac)(x_dec2)\n","\n","    x_dec2 = Conv2D(\n","        num_filters, conv_dim,\n","        padding='same',\n","        name='{}_conv3'.format(block_name))(x_dec2)\n","    x_dec2 = BatchNormalization(\n","        name='{}_bn3'.format(block_name))(x_dec2)\n","    x_dec2 = PReLU(\n","        name='{}_activation3'.format(block_name))(x_dec2)\n","    x_dec2 = Dropout(dropout_frac)(x_dec2)\n","\n","    x_dec2 = Add()([x_dec, x_dec2])\n","\n","    return x_dec2\n","\"\"\""],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["\"\\n# Basic decoder block with Conv, BN and PReLU activation.\\ndef decoder_block_simple(\\n        layer_name, block_name,\\n        num_filters=32,\\n        conv_dim=(3, 3)):\\n\\n    x_dec = Conv2D(\\n        num_filters, conv_dim,\\n        padding='same',\\n        name='{}_conv'.format(block_name))(layer_name)\\n    x_dec = BatchNormalization(\\n        name='{}_bn'.format(block_name))(x_dec)\\n    x_dec = PReLU(\\n        name='{}_activation'.format(block_name))(x_dec)\\n\\n    return x_dec\\n\\n# Decoder block with bottleneck architecture, where middle conv layer\\n# is half the size of first and last, in order to compress representation.\\n# This type of architecture is supposed to retain most useful information.\\ndef decoder_block_bottleneck(\\n        layer_name, block_name,\\n        num_filters=32,\\n        conv_dim=(3, 3),\\n        dropout_frac=0.2):\\n\\n    x_dec = Conv2D(\\n        num_filters, conv_dim,\\n        padding='same',\\n        name='{}_conv1'.format(block_name))(layer_name)\\n    x_dec = BatchNormalization(\\n        name='{}_bn1'.format(block_name))(x_dec)\\n    x_dec = PReLU(\\n        name='{}_activation1'.format(block_name))(x_dec)\\n    x_dec = Dropout(dropout_frac)(x_dec)\\n\\n    x_dec2 = Conv2D(\\n        num_filters // 2, conv_dim,\\n        padding='same',\\n        name='{}_conv2'.format(block_name))(x_dec)\\n    x_dec2 = BatchNormalization(\\n        name='{}_bn2'.format(block_name))(x_dec2)\\n    x_dec2 = PReLU(\\n        name='{}_activation2'.format(block_name))(x_dec2)\\n    x_dec2 = Dropout(dropout_frac)(x_dec2)\\n\\n    x_dec2 = Conv2D(\\n        num_filters, conv_dim,\\n        padding='same',\\n        name='{}_conv3'.format(block_name))(x_dec2)\\n    x_dec2 = BatchNormalization(\\n        name='{}_bn3'.format(block_name))(x_dec2)\\n    x_dec2 = PReLU(\\n        name='{}_activation3'.format(block_name))(x_dec2)\\n    x_dec2 = Dropout(dropout_frac)(x_dec2)\\n\\n    x_dec2 = Add()([x_dec, x_dec2])\\n\\n    return x_dec2\\n\""]},"metadata":{"tags":[]},"execution_count":1}]},{"cell_type":"code","metadata":{"id":"wOCGJefKV9r6"},"source":["\"\"\"\n","# Model is parametrized in a way to enable easy change of decoder_block type,\n","# as this is an argument that can be given a function, like decoder_block_simple.\n","def unet_resnet(input_size, decoder_block,\n","                weights='imagenet',\n","                loss_func='binary_crossentropy',\n","                metrics_list=[my_iou_metric],\n","                use_lovash=False):\n","\n","    # Base model - encoder\n","    base_model = ResNet50(\n","        input_shape=input_size, \n","        include_top=False,\n","        weights=weights)\n","    \n","    # Layers for feature extraction in the encoder part\n","    encoder1 = base_model.get_layer('conv1').output # activation_1\n","    encoder2 = base_model.get_layer('res2c_branch2c').output # activation_10\n","    encoder3 = base_model.get_layer('res3d_branch2c').output # activation_22\n","    encoder4 = base_model.get_layer('res4f_branch2c').output # activation_40\n","    encoder5 = base_model.get_layer('res5c_branch2c').output # activation_40\n","\n","    # Center block\n","    center = decoder_block(\n","        encoder5, 'center', num_filters=512)\n","    concat5 = concatenate([center, encoder5], axis=-1)\n","\n","    # Decoder part.\n","    # Every decoder block processed concatenated output from encoder and decoder part.\n","    # This creates skip connections.\n","    # Afterwards, decoder output is upsampled to dimensions equal to encoder output part.\n","    decoder4 = decoder_block(\n","        concat5, 'decoder4', num_filters=256)\n","    concat4 = concatenate([UpSampling2D()(decoder4), encoder4], axis=-1)\n","\n","    decoder3 = decoder_block(\n","        concat4, 'decoder3', num_filters=128)\n","    concat3 = concatenate([UpSampling2D()(decoder3), encoder3], axis=-1)\n","\n","    decoder2 = decoder_block(\n","        concat3, 'decoder2', num_filters=64)\n","    concat2 = concatenate([UpSampling2D()(decoder2), encoder2], axis=-1)\n","\n","    decoder1 = decoder_block(\n","        concat2, 'decoder1', num_filters=64)\n","    concat1 = concatenate([UpSampling2D()(decoder1), encoder1], axis=-1)\n","\n","    # Final upsampling and decoder block for segmentation.\n","    output = UpSampling2D()(concat1)\n","    output = decoder_block(\n","        output, 'decoder_output', num_filters=32)\n","    output = Conv2D(\n","        1, (1, 1), activation=None, name='prediction')(output)\n","    if not use_lovash:\n","        output = Activation('sigmoid')(output)\n","        \n","    model = Model(base_model.input, output)\n","    model.compile(loss=loss_func, optimizer='adam', metrics=metrics_list)\n","\n","    return model\n","\"\"\""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"n2gnhiubSNUe"},"source":["- 前回使用した実装とはどのように違うのか\n","\n","<デコーダ>\n","1. 前回は2次元畳み込みが2回行われていたのに対して、今回は2次元畳み込みが1回行われている。\n","また、2次元畳み込みの後にバッチ正規化が行われる。\n","\n","<エンコーダ>\n","2. 前回はUpsampling2Dでアップサンプリングを行って、concatenateでダウンサンプリング時に保存した特徴量マップを結合して、 通常の畳み込みを実施している。今回はKerasのResNet50を使用している。\n","ResNetは層が非常に深く、shortcut connectionの導入により勾配の減衰を防ぐ手法である。\n","\n","<比較>\n","- 活性化関数\n","  - 前回 : ReLu + sigmoid\n","  - 今回 : PReLu + sigmoid\n","\n","- Optimizer\n","  - 前回 : Adam\n","  - 今回 : Adam\n","\n","- 損失関数\n","  - 前回 : binary_crossentropy\n","  - 前回 : binary_crossentropy(デフォルト)\n","\n","- 評価関数\n","  - 前回: accuracy\n","  - 今回 : IoU\n","\n","- 転移学習をどのように行っているか\n","1. ResNet50はImageNetで学習した重みをもつ画像分類のモデルの一つである。モデルを訓練する際にweights='imagenet' の引数を指定しており学習した重みにて処理している。"]},{"cell_type":"markdown","metadata":{"id":"9h7_nNVLTm1T"},"source":[""]},{"cell_type":"markdown","metadata":{"id":"JkyLlKkMfsGW"},"source":["### 【問題2】コードの書き換え\n","\n","エンコーダーにResNetが使用されていたコードをVGGに変更してください。"]},{"cell_type":"markdown","metadata":{"id":"XYiZwbpL_vH7"},"source":["__Sprint20_VGG_03-models_pretrained_and_more.ipynb にコードを変更している。__\n","\n","リンク：[Sprint20_VGG](https://github.com/takamotoki/diveintocode-ml/blob/master/Sprint/Term2/Sprint20_VGG_03-models_pretrained_and_more.ipynb)"]},{"cell_type":"markdown","metadata":{"id":"-PgnEDKSfyag"},"source":["### 【問題3】学習・推定\n","\n","ResNetとVGG双方のコードで学習・推定を行い、結果を比較してください。"]},{"cell_type":"markdown","metadata":{"id":"_HjArIzX_fM5"},"source":["- Resnet\n","リンク：[Sprint20_ResNet](https://github.com/takamotoki/diveintocode-ml/blob/master/Sprint/Term2/Sprint20_Resnet_03-models_pretrained_and_more.ipynb)\n","\n","- VGG\n","問題2と同じリンク：[Sprint20_VGG](https://github.com/takamotoki/diveintocode-ml/blob/master/Sprint/Term2/Sprint20_VGG_03-models_pretrained_and_more.ipynb)\n","\n","- 比較結果\n","1. UNet + ResNet　→ Best IoU: 0.5236 at threshold: 0.200\n","2. UNet + VGG16　→ Best IoU: 0.4169 at threshold: 0.200\n","\n","UNet + ResNetがUNet + VGG16と比較して良い結果である。"]},{"cell_type":"markdown","metadata":{"id":"WWQem7UjvBo6"},"source":[""]}]}